<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>Code | AMP-R</title>
		<link rel="stylesheet" href="static/css/style.css" />
	</head>
	<body>
		<nav>
			<a href="/" id="siteTitle"><h1>AMP-R</h1></a>
			<section id="navLinksSection">
				<a href="all.html"><h3>All Peptides</h3></a>
				<a href="anti_gram_positive.html"><h3>Anti-Gram Positive Peptides</h3></a>
				<a href="docked.html"><h3>Docked Peptides</h3></a>
				<h3 id="currentPage">Code</h3>
				<a href="references.html"><h3>References</h3></a>
			</section>
		</nav>

		<h1 style="margin: 30px; font-size: 3.5em; text-align: center">Decoding our Code</h1>

		<main id="codeWriteup">
			<section class="codeWriteupSection">
				<h1>INTRODUCTION</h1>
				<p>
					Given the massive size of AMP-R, we were faced with many mechanical, tedious
					tasks that were highly time-consuming to perform manually. Examples include
					preparing FASTA files from sequences, merging spreadsheets from the DRAMP
					repository, sorting and filtering lists based on certain parameters, etc.
				</p>
				<p>
					To save time and effort, we used <strong>Python</strong> to automate these
					tasks. Our simple Python scripts utilized our
					<a
						target="_blank"
						href="https://github.com/KarishmaKaushikLab/AMP-R/blob/master/utils/full.csv"
						>master spreadsheet</a
					>
					containing information about all peptides to achieve this. All of these scripts
					have been made <em>open-source</em> and you can find them on our
					<a target="_blank" href="https://github.com/KarishmaKaushikLab/AMP-R"
						>GitHub repository</a
					>.
				</p>
				<p>In this section, we shall talk in detail about these scripts.</p>
			</section>
			<section class="codeWriteupSection">
				<h1>GENERATION OF FASTA FILES</h1>
				<p>
					Amongst other things, we pulled peptide sequence data from the
					<a target="_blank" href="http://dramp.cpu-bioinfor.org/">DRAMP repository</a>.
					Using these sequence strings, we intended to generate FASTA files. For example,
					for Pep6 with sequence
					<pre>GNGVLKTISHECNMNTWQFLFTCC</pre>
					the corresponding FASTA file would look like
					<pre>>Peptide_6
GNGVLKTISHECNMNTWQFLFTCC</pre>
					This was an obvious and easy target for automation. We simply loop over all the
					peptides in our spreadsheet in order and then generate a FASTA file with their
					sequence. You can find the script for this
					<a
						href="https://github.com/KarishmaKaushikLab/AMP-R/blob/master/utils/fasta.py"
						target="_blank"
						rel="noopener noreferrer"
						>here</a
					>.
				</p>
				<p>
					Thanks to this, we were able to achieve
					<em>what would have taken months within a fraction of a second</em>.
				</p>
			</section>
			<section class="codeWriteupSection">
				<h1>FILTERING ANTI-GRAM POSITIVE PEPTIDES</h1>
				<p>
					Our target organism, <em>Corynebacterium striatum</em> exhibits anti-Gram
					positive activity. Thus, we were interested in filtering out peptides which
					exhibited the same activity.
				</p>
				<p>
					Our master spreadsheet has a column with a list of activities exhibited by each
					peptide. We simply loop over all peptides and look for the
					<strong>Anti-Gram+</strong> activity.
				</p>
				<p>
					You can find the script for this
					<a
						href="https://github.com/KarishmaKaushikLab/AMP-R/blob/master/scripts/agp_filter/agp_filter.py"
						target="_blank"
						rel="noopener noreferrer"
						>here</a
					>. We also have a dedicated section for peptides exhibiting
					<strong>Anti-Gram+</strong> activity
					<a href="/anti_gram_positive.html">here</a>.
				</p>
			</section>
			<section class="codeWriteupSection">
				<h1>COMBINING OLD & NEW DRAMP LISTS</h1>
				<p>
					We had pulled a list of peptides from the DRAMP repository back in December 2020
					and were working with it. However, in May 2021 we noticed that DRAMP had revised
					the list with more peptides. Thus, we had to incorporate the new peptides into
					our work.
				</p>
				<p>
					The issue was that we had already assigned Pep IDs as per the order in the
					original list, which were being used throughout our project. Unfortunately,
					DRAMP's revised list did not retain that same order as our original one. Thus,
					we would have to sit down and spend a long time reconciling the changes.
				</p>
				<p>
					Thankfully, with a bit of data wrangling, we were able to automate this as well.
					Our Python script first scanned our original list to build a mapping between the
					IDs from the DRAMP database and our own Pep IDs. Next, we scanned through the
					revised list and looked for any peptides which weren't part of our original
					list. Finally, using the mapping we built earlier, we retained our original Pep
					IDs and assigned new ones to the new peptides.
				</p>
				<p>
					You can find the script for this
					<a
						href="https://github.com/KarishmaKaushikLab/AMP-R/blob/master/scripts/dramp_combine_lists/combine.py"
						target="_blank"
						rel="noopener noreferrer"
						>here</a
					>.
				</p>
			</section>
			<section class="codeWriteupSection">
				<h1>SORTING RESIDUES BY INTERACTIONS</h1>
				<p>
					Once we had docked our selected few peptides with our target protein, we wished
					to sort these peptides based on their interactions and docking energy. This
					would result in a much more approachable and useful document that would help
					users of our repository.
				</p>
				<p>
					We assigned priorities to all candidate residues and performed a simple sort
					based on them.
				</p>
				<p>
					Further, we manually grouped peptides based on these interactions. We performed
					an intra-group sort based on docking energy.
				</p>
				<p>
					This part was extremely straightforward and was made even easier with Python's
					excellent
					<a href="https://pandas.pydata.org/" target="_blank" rel="noopener noreferrer"
						>Pandas library</a
					>.You can find the code for this
					<a
						href="https://github.com/KarishmaKaushikLab/AMP-R/tree/master/scripts/residue_sorter"
						target="_blank"
						rel="noopener noreferrer"
						>here</a
					>.
				</p>
			</section>
			<section class="codeWriteupSection">
				<h1>GENERATING WEBSITE ASSETS & RESOURCES</h1>
				<p>
					Our website is a static one. This means that there is no server-side code
					running in the cloud. We simply deliver static HTML over
					<a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer"
						>GitHub Pages</a
					>. We made this choice because we knew that given the size of our database (a
					few thousand items), we could get away with a static website. But we also wanted
					to have search enabled on this repository for convenient and easy access. Thus,
					we built an offline search engine in JavaScript that runs off a compact search
					index that your browser downloads every time you visit our
					<a href="/all.html">All Peptides</a> or
					<a href="/anti_gram_positive.html">Anti-Gram Positive Peptides</a> sections. We
					wrote a
					<a
						href="https://github.com/KarishmaKaushikLab/AMP-R/blob/master/utils/index.py"
						target="_blank"
						rel="noopener noreferrer"
						>Python script</a
					>
					to generate these
					<a
						href="https://github.com/KarishmaKaushikLab/AMP-R/tree/master/static/js"
						target="_blank"
						rel="noopener noreferrer"
						>search indexes</a
					>.
				</p>
				<p>
					This approach, while simplistic and limited, works well for us. Despite
					downloading entire search indexes, our initial page load is in the neighborhood
					of just 250KB, thanks to compression. Secondly, since our search runs within
					your browser itself, it is lightning fast. Finally, we have zero server costs!
				</p>
				<p>
					We also wrote a
					<a
						href="https://github.com/KarishmaKaushikLab/AMP-R/blob/master/utils/thumbs.py"
						target="_blank"
						rel="noopener noreferrer"
						>bit of Python</a
					>
					to generate thumbnails for all the 3D models that you see on the site.
				</p>
			</section>
		</main>
	</body>
</html>
